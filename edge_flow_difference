# retraining_destination_breakdown.py
import numpy as np
import pandas as pd
from pathlib import Path

def retraining_destination_breakdown(F_time_base,
                                     F_time_new,
                                     source_id,
                                     t_start,
                                     names_path="data/ipums_variables.csv",
                                     only_positive=True,
                                     top_n=None):
    """
    For a single `source_id`, compute where the retrained workers go.

    Parameters
    ----------
    F_time_base, F_time_new : list[np.ndarray]
        Per-timestep flow matrices from baseline and treated runs.
        Each F[t] has shape (n_occ, n_occ) with F[i,j] = workers i→j.
    source_id : int
        Occupation whose outgoing retraining flows you want to study.
    t_start : int
        First timestep **included** in the sum (e.g. `t_shock`).
    names_path : str
        CSV containing at least the column “label” with occupation names.
    only_positive : bool, default True
        If True, keep only destinations with Δflow > 0.
    top_n : int or None
        Return only the largest `top_n` Δflows.  None → all.

    Returns
    -------
    pandas.DataFrame  sorted by `delta_flow` (descending)

        target_id | name | baseline_flow | new_flow | delta_flow | share_of_delta
    """
    if len(F_time_base) != len(F_time_new):
        raise ValueError("Runs have different lengths.")

    # stack the flow matrices from t_start onward
    base_stack = np.stack(F_time_base[t_start:], axis=0)  # shape: (T, n, n)
    new_stack  = np.stack(F_time_new [t_start:], axis=0)

    # total flows source -> every j over the window
    base_tot = base_stack[:, source_id, :].sum(axis=0)
    new_tot  = new_stack [:, source_id, :].sum(axis=0)
    delta    = new_tot - base_tot

    # labels & meta
    df_lab   = pd.read_csv(Path(names_path))
    names    = df_lab["label"].values                   :contentReference[oaicite:0]{index=0}

    # build table
    df = pd.DataFrame({
        "target_id"     : np.arange(len(delta)),
        "name"          : names,
        "baseline_flow" : base_tot,
        "new_flow"      : new_tot,
        "delta_flow"    : delta
    })

    if only_positive:
        df = df[df["delta_flow"] > 0]

    # normalise share among *positive* deltas
    total_delta = df["delta_flow"].sum()
    df["share_of_delta"] = df["delta_flow"] / total_delta

    df = df.sort_values("delta_flow", ascending=False)

    if top_n is not None:
        df = df.head(top_n).reset_index(drop=True)

    return df
